{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Callysto.ca Banner](https://github.com/callysto/curriculum-notebooks/blob/master/callysto-notebook-banner-top.jpg?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callysto's Weekly Data Visualization\n",
    "## WeRateDogs inflationary scoring\n",
    "\n",
    "\n",
    "### Reccommended grade level: 9-12\n",
    "\n",
    "### Instructions\n",
    "#### Step 1 (your only step): “Run” the cells to see the graphs\n",
    "Click “Cell” and select “Run All.” This will import the data and run all the code to make this week's data visualizations (scroll to the top after you’ve run the cells). **You don’t need to do any coding**. The two plots generated in this notebook are interactive. You can hover over and click on elements to gain more information.   \n",
    "\n",
    "![instructions](https://github.com/callysto/data-viz-of-the-week/blob/main/images/instructions.png?raw=true)\n",
    "\n",
    "After a code cell runs, a number appears in the top left corner. If the code cell experiences a technical error some red script will appear below the cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About This Notebook\n",
    "\n",
    "Callysto's Weekly Data Visualization is a learning resource that helps Grades 5-12 teachers and students grow and develop data literacy skills. We do this by providing a data visualization, like a graph, and asking teachers and students to interpret it. This companion resource walks learners through how the data visualization is created and interpreted using the data science process. The steps of this process are listed below and applied to each weekly topic.\n",
    "\n",
    "1. Question - What are we trying to answer?\n",
    "2. Gather - Find the data source(s) you will need.\n",
    "3. Organize - Arrange the data so that you can easily explore it.\n",
    "4. Explore - Examine the data to look for evidence to answer our question. This includes creating visualizations.\n",
    "5. Interpret - Explain how the evidence answers our question.\n",
    "6. Communicate - Reflect on the interpretation.\n",
    "\n",
    "### Acknowledgment\n",
    "\n",
    "This project is based off of [this](http://dhmontgomery.com/2017/03/dogrates/) data science exploration using, with permission, a data set of tweets collected by [Greg Baker](https://www.sfu.ca/computing/people/faculty/gregbaker.html), a senior lecturer at [SFU](https://www.sfu.ca) for use in his Computational Data Science course. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Question\n",
    "**Are the WeRateDogs scores suffering from inflation?**\n",
    "\n",
    "<div>\n",
    "    <br><br>\n",
    "<img src=\"./images/brent.png\" width=\"500\"/>\n",
    "    <br><br>\n",
    "</div>\n",
    "\n",
    "[WeRateDogs](https://twitter.com/dog_rates) is a [popular](https://en.wikipedia.org/wiki/WeRateDogs) twitter account that offers humorous dog ratings and has spawned many memes. The twitter exchange above was a popular meme a few years ago, and the account is even [credited](https://www.npr.org/sections/alltechconsidered/2017/04/23/524514526/dogs-are-doggos-an-internet-language-built-around-love-for-the-puppers) with creating or formalizing the \"pupper\" and \"doggo\" lingo used to describe dogs over the internet. Much like 4chan users are credited with creating a 'LOLCAT' pigeon language in the early 2000s.\n",
    "\n",
    "Outside of exploring the history of internet memes, the account can demonstrate the concept of grade inflation. Usually when grade inflation is discussed, it is discussed in context of highschools or universities giving out higher B and A grades leading to a diminishing value or meaning of those grades. Here we will see how scores given out by the WeRateDogs account may or may not be suffering from grade inflation. Hence, our question for this notebook is:\n",
    "* Are the WeRateDogs scores suffering from inflation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Gather\n",
    "\n",
    "We will import the python libraries we need then read in our already collected dataset of WeRateDogs tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import needed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import plotly.express as px\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we read in the collected tweets from a csv file into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the dataset\n",
    "path = os.path.join('datasets', 'dog_rates_tweets.csv')\n",
    "data = pd.read_csv(path, dtype ={'text':str},parse_dates = ['created_at']).set_index(keys='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the last step in the 'gather' step we inspect what we pulled in to make sure everything looks okay and start to understand what our dataset looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are', data.shape[0], 'tweets in the dataset.\\nThe first few rows look like this:')\n",
    "#view the unmutated data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Organize\n",
    "This step will take some work.  Our data does not have a score column. Instead the scores, if they are present, are nested in the text. First we will need to extract scores from our tweets in an automated fashion. It would take far too long and be far too error prone to manually check eight-thousand tweets. Then we will have to do some manual checking.\n",
    "\n",
    "First we create a helper function to find any '*x*/10' scores in a tweet, where *x* is a digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_rating(text):\n",
    "    \"\"\"a helper function to find any 'x/10'\n",
    "    the function only returns the first such score found in a tweet\"\"\"\n",
    "    match = re.search(r'(\\d+(\\.\\d+)?)/10',str(text))\n",
    "    if match:\n",
    "        top, btm = match[0].split('/')\n",
    "        return float(top)/float(btm)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we apply the above function to the *text* column to create a new column consisting only of scores, remove the original text from the dataset, and remove any tweets that don't contain a score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the ratings\n",
    "data['rating'] = data['text'].map(text_to_rating)\n",
    "#drop the actual content of the tweets\n",
    "data = data.drop(['text'], axis =1)\n",
    "#drop entries with no scores found\n",
    "data = data[np.isfinite(data['rating'])]\n",
    "#rename create_at for easy of plotting later\n",
    "data.rename(columns={'created_at':'date created'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we print the data sorted by highest to lowest score to get a picture of the range of scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the data\n",
    "data = data.sort_values(by='rating', ascending = False)\n",
    "#display the data\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the output above, we see that the data has a large range of values and the top few seems particularily large for an out of ten system. Very large datapoints are usually refered to as outliers, depending on the use, the data and the question outliers sometimes need to be removed, but other times are very key to painting an accurate picture of the data. Below, we do remove a number of the largest data points. This was decide by looking at the tweets and seeing if they were valid scores or somthing else. The scores about 14/10 all seemed irrelevant.\n",
    "\n",
    "Sometimes the the large scores were dates:\n",
    "![holiday score](./images/1776.png)\n",
    "\n",
    "\n",
    "Sometimes they were scores scrapped from conversations about scoring:\n",
    "![](./images/meta.png)\n",
    "\n",
    "\n",
    "Sometimes they were honourary:\n",
    "![](./images/honourary.png)\n",
    "\n",
    "This dataset did not contain any genuine scores about 14. However, the web scraping used to collect the data did not find every single tweet, so it is possibly missing valid 15/10 scores for especially good dogs.\n",
    "\n",
    "the low scores, except for the 0/10, seemed to be genuine ratings. Many low scores, however, were rating animals other than dogs. For our purposes we will consider those to be true ratings.  However, depending on how the question is interpreted it could be fair to remove them.\n",
    "\n",
    "Many low rates given were like this one given to a goat:\n",
    "![](./images/goat.png)\n",
    "\n",
    "Since this data exploration isn't a serious one we can decide relatively freely on the criteria for dropping data points. However, in hard science or research data should never be removed without careful thought. Changing key points of data can grosly change the results. \n",
    "\n",
    "Our last step in organizing the date is removing the outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove largest scores points\n",
    "data_cleaned = data.iloc[13:-3].copy()\n",
    "# print the data\n",
    "data_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Explore\n",
    "\n",
    "In exploring the data we will create some plots. First we create a helper function to make a scatterplot with a line of 'best fit' running through the points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plot(data):\n",
    "    \"\"\"A simple function that will take in a dataframe formatted like ours \n",
    "    and produce a scatterplot with best fit line\n",
    "    input:\n",
    "        a pandas dataframe with 'rating' and 'date created columns\n",
    "    return:\n",
    "        a plotly express scatterplot with best fit line(untitled)\n",
    "    \"\"\"\n",
    "    fig = px.scatter(data, x='date created', y='rating', trendline='ols')\n",
    "    #highlight the best fit line in red to make it more visible\n",
    "    fig.data[1].update(line_color='red')\n",
    "    #show the tweets in the legend\n",
    "    fig['data'][0]['showlegend']=True\n",
    "    fig['data'][0]['name']='Tweet'\n",
    "    # show the best fit line in the legend\n",
    "    fig['data'][1]['showlegend']=True\n",
    "    fig['data'][1]['name']='Best Fit Line (OLS)'\n",
    "    fig['data'][1]['visible']='legendonly'\n",
    "    fig.update_layout(showlegend=True)\n",
    "    #show the plot\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4(a). Explore - data with outliers \n",
    "First we'll create and show the plot from the dataset of scores without filtering out the outliers.\n",
    "\n",
    "**Click on the 'Best Fit Line(OLS)' entry on the legend located on the right hand side of the plot to show the best fit line**\n",
    "\n",
    "After looking at the data with and without the best fit line do you think the *WeRateDogs scores suffering from inflation?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a plot without the outliers removed\n",
    "fig = create_plot(data)\n",
    "# add an appropriate title to the plot\n",
    "fig.update_layout(title = 'Plot without outliers removed')\n",
    "# show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the outliers are not removed the visual is very hard to make out any detail and the line best fitting the data has a slope of $2.8 \\times 10^{-9}$\n",
    "\n",
    "### 4(b) Explore - data without outliers\n",
    "below we'll generate the plot with the outliers removed and expect to see a much clearer image of the data. \n",
    "\n",
    "Note: **The goal of removing outliers is not to make a clearer plot**. The goal of removing outliers was to create a more accurate dataset to answer our question. One should not strive to create an aesthetic plot at the expense of accuracy.\n",
    "\n",
    "**Click on the 'Best Fit Line(OLS)' entry on the legend located on the right hand side of the plot to show the best fit line**\n",
    "\n",
    "After looking at the data with and without the best fit line do you think the *WeRateDogs scores suffering from inflation?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crete a plot with the outliers removed\n",
    "fig = create_plot(data_cleaned)\n",
    "# add an appropriate title to the plot\n",
    "fig.update_layout(title = 'WeRateDogs Scores Given Versus Time')\n",
    "# show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the outliers are removed the visual clearly shows seperate scores and the slope is now $3.4\\times 10^{-9}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Interpret\n",
    "The positive slope on the red line reveals that scores have been increasing as time has gone on. This line is the line through the data points that minimizes the squared y-value distance between the line and data points. This method is called *Ordinary Least Squares* and is a common method for approximating a straight line through a dataset to reveal a relationship. In this case the relationship is the more recent the grade the higher the score (on average).\n",
    "\n",
    "We can conclude that grade inflation has been occuring in the WeRateDogs scores.\n",
    "\n",
    "However, removing the outliers did change the amount of that slope. Do you think they were fairly removed? Why or why not?\n",
    "\n",
    "Do you think the low scores in tweets that contained images of animals other than dogs should have been removed?\n",
    "\n",
    "Also this data is missing tweets from mid 2018. Do you think they'd change the best fit line?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Communicate\n",
    "Below we will reflect on the new information that is presented from the data. When we look at the evidence, think about what you perceive about the information. Is this perception based on what the evidence shows? If others were to view it, what perceptions might they have? These writing prompts can help you reflect.\n",
    "\n",
    "* I used to think __ but now I know __.\n",
    "* I wish I knew more about __.\n",
    "* This visualization reminds me of __.\n",
    "* I really like __.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Callysto.ca License](https://github.com/callysto/curriculum-notebooks/blob/master/callysto-notebook-banner-bottom.jpg?raw=true)](https://github.com/callysto/curriculum-notebooks/blob/master/LICENSE.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
