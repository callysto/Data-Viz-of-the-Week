{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Callysto.ca Banner](https://github.com/callysto/curriculum-notebooks/blob/master/callysto-notebook-banner-top.jpg?raw=true)\n",
    "\n",
    "<a href=\"https://hub.callysto.ca/jupyter/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2Fcallysto%2Fdata-viz-of-the-week&branch=main&subPath=stock-prices/stock-prices-ML.ipynb&depth=1\" target=\"_parent\"><img src=\"https://raw.githubusercontent.com/callysto/curriculum-notebooks/master/open-in-callysto-button.svg?sanitize=true\" width=\"123\" height=\"24\" alt=\"Open in Callysto\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callysto’s Weekly Data Visualization\n",
    "\n",
    "## Stock Prices ML\n",
    "\n",
    "### Recommended Grade levels: \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "Click \"Cell\" and select \"Run All\".\n",
    "\n",
    "This will import the data and run all the code, so you can see this week's data visualization. Scroll back to the top after you’ve run the cells.\n",
    "\n",
    "![instructions](https://github.com/callysto/data-viz-of-the-week/blob/main/images/instructions.png?raw=true)\n",
    "\n",
    "**You don't need to do any coding to view the visualizations**.\n",
    "\n",
    "The plots generated in this notebook are interactive. You can hover over and click on elements to see more information. \n",
    "\n",
    "Email contact@callysto.ca if you experience issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About this Notebook\n",
    "\n",
    "Callysto's Weekly Data Visualization is a learning resource that aims to develop data literacy skills. We provide Grades 5-12 teachers and students with a data visualization, like a graph, to interpret. This companion resource walks learners through how the data visualization is created and interpreted by a data scientist. \n",
    "\n",
    "The steps of the data analysis process are listed below and applied to each weekly topic.\n",
    "\n",
    "1. Question - What are we trying to answer?\n",
    "2. Gather - Find the data source(s) you will need. \n",
    "3. Organize - Arrange the data, so that you can easily explore it. \n",
    "4. Explore - Examine the data to look for evidence to answer the question. This includes creating visualizations. \n",
    "5. Interpret - Describe what's happening in the data visualization. \n",
    "6. Communicate - Explain how the evidence answers the question. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "How can we utilize machine learning to leverage historical data for predictive analysis using stock-data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal\n",
    "\n",
    "We will be using machine-learning to see if we can create models that would be useful in predicting stock prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background\n",
    "\n",
    "Understanding financial literacy in the form of stocks at a young age cultivates a foundation for long-term financial stability, promoting individuals to make informed decisions, foster savings habits, and capitalize on the compounding benefits of early investments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather\n",
    "\n",
    "Stock prices in this notebook are obtained using the Python library [yfinance](https://pypi.org/project/yfinance/) and stock symbols and names are obtained from the [Nasdaq](https://www.nasdaq.com/market-activity/stocks/screener)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Disclaimer**\n",
    "\n",
    "This notebook is **strictly** for educational and informational purposes and does not constitute financial advice, recommendation, or endorsement. The content presented here is not intended to influence any investment decisions, and readers are strongly advised to seek independent financial advice and conduct their own research before making any investment choices. The authors and contributors of this notebook shall not be held responsible for any financial losses or decisions made based on the information provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code: \n",
    "\n",
    "Run the code cells below to import the libraries we need for this project. Libraries are pre-made code that make it easier to analyze our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "except:\n",
    "    !pip install xgboost\n",
    "    from xgboost import XGBClassifier\n",
    "\n",
    "try:\n",
    "    import yfinance as yf\n",
    "except:\n",
    "    !pip install yfinance\n",
    "    import yfinance as yf\n",
    "\n",
    "print(\"Libaries imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = yf.download(\"^GSPC\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Tomorrow\"] = data[\"Close\"].shift(-1)\n",
    "data[\"Target\"] = (data[\"Tomorrow\"] > data[\"Close\"]).astype(int)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.index >= \"2000-01-01\"]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_data = data.copy()\n",
    "bad_data = bad_data.dropna()\n",
    "\n",
    "bad_model = RandomForestClassifier(n_estimators=100, min_samples_split=100, random_state=42)\n",
    "\n",
    "train = bad_data.iloc[:-100]\n",
    "test = bad_data.iloc[-100:]\n",
    "\n",
    "predictors = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"Tomorrow\", \"Target\"]\n",
    "bad_model.fit(train[predictors], train[\"Target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = bad_model.predict(test[predictors])\n",
    "predictions = pd.Series(predictions, index=test.index)\n",
    "precision_score(test[\"Target\"], predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, min_samples_split=100, random_state=42)\n",
    "\n",
    "train = data.iloc[:-100]\n",
    "test = data.iloc[-100:]\n",
    "\n",
    "predictors = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "model.fit(train[predictors], train[\"Target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test[predictors])\n",
    "predictions = pd.Series(predictions, index=test.index)\n",
    "precision_score(test[\"Target\"], predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([test[\"Target\"], predictions], axis=1)\n",
    "combined.rename(columns={\"Target\": \"Actual\", 0: \"Predicted\"}, inplace=True)\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(combined, x=combined.index, y=['Actual', 'Predicted'], labels={'index': 'Date', 'value': 'Values'},title='Actual vs Predicted').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = data.copy()\n",
    "\n",
    "predictors = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "target = \"Target\"\n",
    "\n",
    "for col in predictors[:4]:\n",
    "    data_copy[col + ' Rolling Mean'] = data_copy[col].rolling(window=5).mean()\n",
    "\n",
    "data_copy.dropna(inplace=True)\n",
    "data_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_copy[predictors + [col + ' Rolling Mean' for col in predictors[:4]]]\n",
    "y = data_copy[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('imputer', SimpleImputer(strategy=\"mean\")),('classifier', XGBClassifier(random_state=42))])\n",
    "param_grid = {'classifier__n_estimators': [50, 100, 200],'classifier__learning_rate': [0.01, 0.1, 0.2],'classifier__max_depth': [3, 4, 5]}\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, scoring='precision', cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "predictions = best_model.predict(X_test)\n",
    "precision = precision_score(y_test, predictions)\n",
    "\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Precision Score:\", precision)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
